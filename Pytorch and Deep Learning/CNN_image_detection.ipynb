{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "ds = pd.read_csv('/home/kush/Downloads/mnist_train.csv').values\n",
    "print ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "#(batch, depth , height , width)\n",
    "X_train = ds[:10000, 1:].reshape((-1, 1, 28, 28)) / 255.0\n",
    "y_train = ds[:10000, 0]\n",
    "\n",
    "X_test = ds[15000:15200, 1:].reshape((-1, 1, 28, 28)) / 255.0\n",
    "y_test = ds[15000:15200, 0]\n",
    "# y_train = one_hot(y_train_labels, 10)\n",
    "\n",
    "print X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height/depth\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = F.softmax(self.out(x))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD needs more (like x100 more!) learning rate.\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.005)   # optimize all cnn parameters\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn(torch.FloatTensor(X_train[9:10])).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(train, labels, batch_size=10):\n",
    "    start = 0\n",
    "    stop = start + batch_size\n",
    "    while start < train.shape[0]:\n",
    "        yield Variable(torch.FloatTensor(train[start:stop]), requires_grad=True), Variable(torch.LongTensor(labels[start:stop]))\n",
    "        start = stop\n",
    "        stop = start + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for s, (ix, iy) in enumerate(make_batch(X_train, y_train, batch_size=512)):\n",
    "#?    print s, ix.shape, iy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: ', 0, '| Step: ', 0, '| Acc: ', 94.0)\n",
      "('Epoch: ', 1, '| Step: ', 0, '| Acc: ', 95.5)\n",
      "('Epoch: ', 2, '| Step: ', 0, '| Acc: ', 96.5)\n",
      "('Epoch: ', 3, '| Step: ', 0, '| Acc: ', 96.0)\n",
      "('Epoch: ', 4, '| Step: ', 0, '| Acc: ', 98.5)\n",
      "('Epoch: ', 5, '| Step: ', 0, '| Acc: ', 96.5)\n",
      "('Epoch: ', 6, '| Step: ', 0, '| Acc: ', 97.0)\n",
      "('Epoch: ', 7, '| Step: ', 0, '| Acc: ', 96.5)\n",
      "('Epoch: ', 8, '| Step: ', 0, '| Acc: ', 95.0)\n",
      "('Epoch: ', 9, '| Step: ', 0, '| Acc: ', 97.0)\n",
      "('Epoch: ', 10, '| Step: ', 0, '| Acc: ', 97.0)\n",
      "('Epoch: ', 11, '| Step: ', 0, '| Acc: ', 97.5)\n",
      "('Epoch: ', 12, '| Step: ', 0, '| Acc: ', 97.0)\n",
      "('Epoch: ', 13, '| Step: ', 0, '| Acc: ', 99.0)\n",
      "('Epoch: ', 14, '| Step: ', 0, '| Acc: ', 97.0)\n",
      "('Epoch: ', 15, '| Step: ', 0, '| Acc: ', 97.0)\n",
      "('Epoch: ', 16, '| Step: ', 0, '| Acc: ', 98.5)\n",
      "('Epoch: ', 17, '| Step: ', 0, '| Acc: ', 96.5)\n",
      "('Epoch: ', 18, '| Step: ', 0, '| Acc: ', 97.0)\n",
      "('Epoch: ', 19, '| Step: ', 0, '| Acc: ', 98.5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(20):\n",
    "    for step, (b_x, b_y) in enumerate(make_batch(X_train, y_train, 128)):   # gives batch data, normalize x when iterate train_loader\n",
    "        # print step,\n",
    "        output = cnn(b_x)               # cnn output\n",
    "        # print output.size(), output.sum(dim=0)\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        \n",
    "        #for params in cnn.parameters():\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            test_output = cnn(torch.FloatTensor(X_test))\n",
    "            outs = test_output.data.numpy().argmax(axis=1)\n",
    "            acc = (outs == y_test).sum()*100.0 / test_output.shape[0]\n",
    "            # pred_y = torch.max(test_output, 1)[1].data.squeeze().numpy()\n",
    "            # accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| Step: ', step, '| Acc: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Visualised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print cnn.state_dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1.0.weight', 'conv1.0.bias', 'conv2.0.weight', 'conv2.0.bias', 'out.weight', 'out.bias']\n"
     ]
    }
   ],
   "source": [
    "print cnn.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "conv_01 = cnn.state_dict()['conv1.0.weight']\n",
    "print conv_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e0924d950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "for ix in range(conv_01.shape[0]):\n",
    "    plt.subplot(4, 4, ix+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(conv_01[ix].reshape((5, 5)), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
